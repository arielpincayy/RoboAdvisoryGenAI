{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9987643",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"apikey\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb60d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 08:06:44.328061: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/ariel/Escritorio/proyectos/RoboAdvisoryGenAI/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764076010.685481   35442 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1709 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Reinicializando recursos NLTK despu√©s de deserializaci√≥n...\n",
      "üì• Descargando recurso NLTK: wordnet\n",
      "üì• Descargando recurso NLTK: omw-1.4\n",
      "‚úÖ TextPreprocessor deserializado correctamente\n",
      "üìÇ Cargando Word2Vec desde pipelines/word2vec_model.bin\n",
      "ü§ñ Cargando modelo SBERT: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 08:07:08.905484: I external/local_xla/xla/service/service.cc:163] XLA service 0x73fd600024f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-25 08:07:08.905496: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-11-25 08:07:08.916082: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-25 08:07:08.955773: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n",
      "I0000 00:00:1764076029.221721   35652 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/home/ariel/Escritorio/proyectos/RoboAdvisoryGenAI/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ RESULTADOS üîπ\n",
      "Sentimientos: {'GLOVE': {'neg': 4.971271394538235e-08, 'neu': 1.0333885830382528e-10, 'pos': 1.0}, 'SBERT': {'neg': 1.925584865170027e-11, 'neu': 2.604151116969433e-09, 'pos': 1.0}, 'Word2Vec': {'neg': 2.2951690326067364e-08, 'neu': 2.3197045413009265e-12, 'pos': 1.0}}\n",
      "Promedio positividad: 1.0\n",
      "Score modelo recomendaci√≥n: 1.0\n",
      "Decisi√≥n del modelo: APROBAR\n",
      "\n",
      "--- An√°lisis GPT ---\n",
      "\n",
      "1. Se debe otorgar la tarjeta de cr√©dito.\n",
      "2. El cliente muestra una actitud positiva y agradecida, lo cual indica una buena disposici√≥n para mantener una relaci√≥n financiera.\n",
      "3. Caracter√≠sticas clave: historial de pagos positivo, bajo nivel de endeudamiento, alta actividad de transacciones, estabilidad laboral y satisfacci√≥n con el servicio al cliente.\n",
      "4. Recomendaci√≥n final: APROBAR\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from gensim.models import Word2Vec\n",
    "import joblib  # <-- Usamos joblib\n",
    "\n",
    "# ===== CONFIG =====\n",
    "API_KEY = api_key\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"‚ö†Ô∏è No se encontr√≥ la variable de entorno OPENAI_API_KEY\")\n",
    "\n",
    "PATH_PIPELINE = \"pipelines\"\n",
    "PATH_MODELS = \"models\"\n",
    "PATH_DATA = \"data\"\n",
    "\n",
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, use_bigrams=True, use_trigrams=True, glove_path=None,\n",
    "                 sbert_model_name='all-MiniLM-L6-v2', w2v_model_path=None):\n",
    "        self.use_bigrams = use_bigrams\n",
    "        self.use_trigrams = use_trigrams\n",
    "        self.glove_path = glove_path\n",
    "        self.glove = {}\n",
    "        self.sbert_model_name = sbert_model_name\n",
    "        self.sbert_model = None\n",
    "        self.w2v_model = None\n",
    "        self.w2v_model_path = w2v_model_path\n",
    "\n",
    "        # Inicializar recursos NLTK\n",
    "        self._ensure_nltk_resources()\n",
    "        self._init_nltk_components()\n",
    "\n",
    "    # ----------------------------\n",
    "    # M√©todos de inicializaci√≥n\n",
    "    # ----------------------------\n",
    "    def _ensure_nltk_resources(self):\n",
    "        import nltk\n",
    "        resources = ['punkt', 'stopwords', 'wordnet', 'omw-1.4']\n",
    "        for resource in resources:\n",
    "            try:\n",
    "                if resource == 'punkt':\n",
    "                    nltk.data.find('tokenizers/punkt')\n",
    "                else:\n",
    "                    nltk.data.find(f'corpora/{resource}')\n",
    "            except LookupError:\n",
    "                print(f\"Descargando recurso NLTK: {resource}\")\n",
    "                nltk.download(resource, quiet=True)\n",
    "\n",
    "    def _init_nltk_components(self):\n",
    "        from nltk.corpus import stopwords\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # ----------------------------\n",
    "    # Utilidades de procesamiento\n",
    "    # ----------------------------\n",
    "    def _clean_text(self, text):\n",
    "        import re\n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r\"http\\S+\", \"\", text)\n",
    "        text = re.sub(r\"[^a-z√°√©√≠√≥√∫√º√± ]\", \"\", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        return text\n",
    "\n",
    "    def _get_wordnet_pos(self, tag):\n",
    "        from nltk.corpus import wordnet\n",
    "        if tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "\n",
    "    def _tokenize_series(self, series):\n",
    "        from nltk import pos_tag, ngrams\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        all_tokens = []\n",
    "        for text in series:\n",
    "            text_clean = self._clean_text(text)\n",
    "            tokens = word_tokenize(text_clean)\n",
    "            tokens = [t for t in tokens if t.isalpha() and t not in self.stop_words]\n",
    "            pos_tags = pos_tag(tokens)\n",
    "            lemmas = [self.lemmatizer.lemmatize(t, self._get_wordnet_pos(pos)) for t, pos in pos_tags]\n",
    "\n",
    "            # n-grams\n",
    "            ngram_tokens = lemmas.copy()\n",
    "            if self.use_bigrams:\n",
    "                ngram_tokens.extend(['_'.join(bg) for bg in ngrams(lemmas, 2)])\n",
    "            if self.use_trigrams:\n",
    "                ngram_tokens.extend(['_'.join(tg) for tg in ngrams(lemmas, 3)])\n",
    "            all_tokens.append(ngram_tokens)\n",
    "        return all_tokens\n",
    "\n",
    "    def _avg_vector(self, tokens, model):\n",
    "        vecs = [model.wv[w] for w in tokens if w in model.wv]\n",
    "        return np.mean(vecs, axis=0) if vecs else np.zeros(model.vector_size)\n",
    "\n",
    "    def _load_glove(self):\n",
    "        self.glove = {}\n",
    "        with open(self.glove_path, 'r', encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                self.glove[word] = vector\n",
    "\n",
    "    def _avg_glove(self, tokens):\n",
    "        vecs = [self.glove[w] for w in tokens if w in self.glove]\n",
    "        return np.mean(vecs, axis=0) if vecs else np.zeros(100)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Fit y transform\n",
    "    # ----------------------------\n",
    "    def fit(self, X, y=None):\n",
    "        print(\"üîÑ Entrenando TextPreprocessor...\")\n",
    "        self.X_tokens_ = self._tokenize_series(X)\n",
    "\n",
    "        # Word2Vec\n",
    "        print(\"üìù Entrenando Word2Vec...\")\n",
    "        self.w2v_model = Word2Vec(\n",
    "            sentences=self.X_tokens_,\n",
    "            vector_size=100,\n",
    "            window=5,\n",
    "            min_count=2,\n",
    "            workers=1\n",
    "        )\n",
    "\n",
    "        if self.w2v_model_path:\n",
    "            self.w2v_model.save(self.w2v_model_path)\n",
    "            print(f\"‚úÖ Word2Vec guardado en {self.w2v_model_path}\")\n",
    "\n",
    "        # Cargar GloVe si existe\n",
    "        if self.glove_path:\n",
    "            self._load_glove()\n",
    "\n",
    "        # Cargar SBERT\n",
    "        print(\"ü§ñ Cargando modelo SBERT...\")\n",
    "        self.sbert_model = SentenceTransformer(self.sbert_model_name)\n",
    "        print(\"‚úÖ TextPreprocessor entrenado exitosamente\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        # Cargar Word2Vec si no est√° en memoria\n",
    "        if self.w2v_model is None and self.w2v_model_path:\n",
    "            if os.path.exists(self.w2v_model_path):\n",
    "                self.w2v_model = Word2Vec.load(self.w2v_model_path)\n",
    "            else:\n",
    "                raise ValueError(\"No se encontr√≥ el modelo Word2Vec. Ejecuta fit() primero.\")\n",
    "\n",
    "        if self.sbert_model is None:\n",
    "            self.sbert_model = SentenceTransformer(self.sbert_model_name)\n",
    "\n",
    "        tokens = self._tokenize_series(X)\n",
    "        X_w2v = np.array([self._avg_vector(t, self.w2v_model) for t in tokens])\n",
    "        X_glove = np.array([self._avg_glove(t) for t in tokens]) if self.glove else None\n",
    "        X_sbert = self.sbert_model.encode(X.tolist(), batch_size=32, show_progress_bar=False)\n",
    "\n",
    "        return {'w2v': X_w2v, 'glove': X_glove, 'sbert': X_sbert}\n",
    "\n",
    "    # ----------------------------\n",
    "    # Serializaci√≥n segura\n",
    "    # ----------------------------\n",
    "    def __getstate__(self):\n",
    "        state = self.__dict__.copy()\n",
    "        state['w2v_model'] = None\n",
    "        state['sbert_model'] = None\n",
    "        state['stop_words'] = None\n",
    "        state['lemmatizer'] = None\n",
    "        return state\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        self.__dict__.update(state)\n",
    "        self.w2v_model = None\n",
    "        self.sbert_model = None\n",
    "        print(\"üîÑ Reinicializando recursos NLTK...\")\n",
    "        self._ensure_nltk_resources()\n",
    "        self._init_nltk_components()\n",
    "        print(\"‚úÖ TextPreprocessor deserializado correctamente\")\n",
    "\n",
    "\n",
    "class DateFeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Genera la columna 'DaysSinceLast' basada en la diferencia de fechas.\n",
    "    Debe ejecutarse ANTES de DropColumns.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Creamos una copia para no afectar el dataframe original fuera del pipeline\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Verificamos que las columnas existan antes de operar\n",
    "        if 'TransactionDate' in X.columns and 'PreviousTransactionDate' in X.columns:\n",
    "            # Asegurar tipo datetime\n",
    "            X['TransactionDate'] = pd.to_datetime(X['TransactionDate'])\n",
    "            X['PreviousTransactionDate'] = pd.to_datetime(X['PreviousTransactionDate'])\n",
    "            \n",
    "            # Calcular diferencia\n",
    "            # Nota: Seg√∫n tu l√≥gica es Previous - Transaction\n",
    "            X['TimeSinceLastTransaction'] = X['PreviousTransactionDate'] - X['TransactionDate']\n",
    "            \n",
    "            # Convertir a d√≠as (segundos totales / 86400)\n",
    "            X['DaysSinceLast'] = X['TimeSinceLastTransaction'].dt.total_seconds() / 86400\n",
    "            \n",
    "        return X\n",
    "\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Elimina columnas innecesarias del dataset de clientes.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.columns = [\n",
    "            'CustomerID', 'Id Complain', 'Id Interaction', 'date_received', \n",
    "            'Survey date', 'Twitter', 'NPS', 'product', 'sub_product', \n",
    "            'issue', 'sub_issue', 'Gender', 'TransactionID', 'AccountID', \n",
    "            'DeviceID', 'IP Address', 'MerchantID', \"TransactionDate\",\n",
    "            \"PreviousTransactionDate\", 'TimeSinceLastTransaction'\n",
    "        ]\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.columns, errors='ignore')\n",
    "\n",
    "\n",
    "class DynamicPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.num_cols = []\n",
    "        self.cat_cols = []\n",
    "        self.num_scaler = MinMaxScaler()\n",
    "        self.cat_encoder = OneHotEncoder(sparse_output=False)\n",
    "        self.cat_feature_names = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.num_cols = X.select_dtypes(include=['float64','int64']).columns.tolist()\n",
    "        self.cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "        \n",
    "        if self.num_cols:\n",
    "            self.num_scaler.fit(X[self.num_cols])\n",
    "        if self.cat_cols:\n",
    "            self.cat_encoder.fit(X[self.cat_cols])\n",
    "            self.cat_feature_names = self.cat_encoder.get_feature_names_out(self.cat_cols)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        num_part = self.num_scaler.transform(X[self.num_cols]) if self.num_cols else np.empty((len(X),0))\n",
    "        cat_part = self.cat_encoder.transform(X[self.cat_cols]) if self.cat_cols else np.empty((len(X),0))\n",
    "        data = np.hstack([num_part, cat_part])\n",
    "        columns = self.num_cols + list(self.cat_feature_names)\n",
    "        return pd.DataFrame(data, columns=columns, index=X.index)\n",
    "\n",
    "\n",
    "# ===== CLASE CREDITADVISOR =====\n",
    "class CreditAdvisor:\n",
    "    def __init__(self, api_key: str):\n",
    "        # Cargar modelos de sentimiento\n",
    "        self.model_glove = load_model(os.path.join(PATH_MODELS, \"2/GLOVE.keras\"))\n",
    "        self.model_sbert = load_model(os.path.join(PATH_MODELS, \"2/SBERT.keras\"))\n",
    "        self.model_w2v = load_model(os.path.join(PATH_MODELS, \"2/Word2Vec.keras\"))\n",
    "        # Modelo de recomendaci√≥n\n",
    "        self.model_recommend = load_model(os.path.join(PATH_MODELS, \"1/recommend.keras\"))\n",
    "        # Pipelines\n",
    "        self.text_pipeline = joblib.load(os.path.join(PATH_PIPELINE, \"text_pipeline.joblib\"))  # <-- joblib\n",
    "        self.data_pipeline = joblib.load(os.path.join(PATH_PIPELINE, \"pipeline_bankchurner_preprocessing.joblib\"))\n",
    "        # Cliente OpenAI\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "\n",
    "    def analyze_client(self, raw_text: str, client_row: pd.Series):\n",
    "        # Preprocesar texto\n",
    "        text_features = self.text_pipeline.transform(pd.Series([raw_text]))\n",
    "        emb_w2v = text_features['w2v']\n",
    "        emb_glove = text_features['glove']\n",
    "        emb_sbert = text_features['sbert']\n",
    "\n",
    "        # Predicci√≥n de sentimientos\n",
    "        pred_glove = self.model_glove.predict(emb_glove, verbose=0)[0]\n",
    "        pred_sbert = self.model_sbert.predict(emb_sbert, verbose=0)[0]\n",
    "        pred_w2v = self.model_w2v.predict(emb_w2v, verbose=0)[0]\n",
    "\n",
    "        sentiment_results = {\n",
    "            \"GLOVE\": {\"neg\": float(pred_glove[0]), \"neu\": float(pred_glove[1]), \"pos\": float(pred_glove[2])},\n",
    "            \"SBERT\": {\"neg\": float(pred_sbert[0]), \"neu\": float(pred_sbert[1]), \"pos\": float(pred_sbert[2])},\n",
    "            \"Word2Vec\": {\"neg\": float(pred_w2v[0]), \"neu\": float(pred_w2v[1]), \"pos\": float(pred_w2v[2])}\n",
    "        }\n",
    "        avg_positive = np.mean([pred_glove[2], pred_sbert[2], pred_w2v[2]])\n",
    "\n",
    "        # Procesar datos del cliente\n",
    "        df_input = client_row.to_frame().T\n",
    "        df_processed = self.data_pipeline.transform(df_input)\n",
    "\n",
    "        # Modelo de recomendaci√≥n\n",
    "        credit_score = float(self.model_recommend.predict(df_processed, verbose=0)[0][0])\n",
    "        decision = \"APROBAR\" if credit_score >= 0.6 else \"RECHAZAR\"\n",
    "\n",
    "        # Prompt para GPT\n",
    "        system_prompt = (\n",
    "            \"Eres un analista financiero especializado en riesgo crediticio. \"\n",
    "            \"Tu tarea es dar una recomendaci√≥n final, breve y clara, sobre otorgar una tarjeta de cr√©dito. \"\n",
    "            \"Eval√∫a los sentimientos del cliente y su perfil financiero, \"\n",
    "            \"pero enf√≥cate en la conclusi√≥n pr√°ctica. Responde en tono profesional y conciso.\"\n",
    "        )\n",
    "\n",
    "        user_prompt = f\"\"\"\n",
    "Cliente:\n",
    "{client_row.to_dict()}\n",
    "\n",
    "An√°lisis de sentimiento:\n",
    "- GloVe ‚Üí Neg: {pred_glove[0]:.2f}, Neutro: {pred_glove[1]:.2f}, Pos: {pred_glove[2]:.2f}\n",
    "- SBERT ‚Üí Neg: {pred_sbert[0]:.2f}, Neutro: {pred_sbert[1]:.2f}, Pos: {pred_sbert[2]:.2f}\n",
    "- Word2Vec ‚Üí Neg: {pred_w2v[0]:.2f}, Neutro: {pred_w2v[1]:.2f}, Pos: {pred_w2v[2]:.2f}\n",
    "Promedio de positividad general: {avg_positive:.2f}\n",
    "\n",
    "Modelo de recomendaci√≥n:\n",
    "- Score del modelo: {credit_score:.2f}\n",
    "- Umbral de aprobaci√≥n: 0.60\n",
    "- Decisi√≥n autom√°tica del modelo: {decision}\n",
    "\n",
    "Texto del cliente:\n",
    "\"{raw_text}\"\n",
    "\n",
    "Con base en todo lo anterior:\n",
    "1. Indica si se debe otorgar la tarjeta de cr√©dito.\n",
    "2. Da una breve justificaci√≥n (m√°ximo 3 frases).\n",
    "3. Menciona 5 caracter√≠sticas claves que pueden influir en la decisi√≥n y por qu√© lo son.\n",
    "4. Finaliza con: 'Recomendaci√≥n final: APROBAR' o 'Recomendaci√≥n final: RECHAZAR'.\n",
    "\"\"\"\n",
    "\n",
    "        # Llamada a GPT\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            top_p=0.7,\n",
    "            max_tokens=300,\n",
    "            frequency_penalty=0.3,\n",
    "            presence_penalty=0.2,\n",
    "        )\n",
    "\n",
    "        explanation = response.choices[0].message.content.strip()\n",
    "\n",
    "        return {\n",
    "            \"sentiment\": sentiment_results,\n",
    "            \"avg_positive\": avg_positive,\n",
    "            \"credit_score\": credit_score,\n",
    "            \"decision_model\": decision,\n",
    "            \"gpt_explanation\": explanation\n",
    "        }\n",
    "\n",
    "\n",
    "# ===== EJEMPLO DE PRUEBA =====\n",
    "if __name__ == \"__main__\":\n",
    "    advisor = CreditAdvisor(api_key=API_KEY)\n",
    "\n",
    "    # Cargar dataset\n",
    "    df = pd.read_csv(os.path.join(PATH_DATA, \"BankChurners_merged.csv\"))\n",
    "    df.drop(columns=['NPS'], inplace=True)\n",
    "    df = df.dropna(subset=['Twitter'])\n",
    "\n",
    "    # Elegir un cliente\n",
    "    client_row = df.iloc[5].drop('Twitter')\n",
    "    text_input = df.iloc[5]['Twitter']\n",
    "\n",
    "    # Ejecutar an√°lisis\n",
    "    result = advisor.analyze_client(text_input, client_row)\n",
    "\n",
    "    # Mostrar resultados\n",
    "    print(\"\\nüîπ RESULTADOS üîπ\")\n",
    "    print(\"Sentimientos:\", result[\"sentiment\"])\n",
    "    print(\"Promedio positividad:\", result[\"avg_positive\"])\n",
    "    print(\"Score modelo recomendaci√≥n:\", result[\"credit_score\"])\n",
    "    print(\"Decisi√≥n del modelo:\", result[\"decision_model\"])\n",
    "    print(\"\\n--- An√°lisis GPT ---\\n\")\n",
    "    print(result[\"gpt_explanation\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
